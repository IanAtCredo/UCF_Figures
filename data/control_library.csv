Control ID,Control Label,Description,Associated Risk Scenarios,Risk Types Addressed,Policy Requirements Relationship
CREDO-001,Establish AI system access controls,"Implement comprehensive access management including role-based access control (RBAC), authentication mechanisms, and audit logging for AI models and associated resources.
","Compromised personally identifiable information, Compromised sensitive information",- Privacy,
CREDO-009,Establish AI system documentation framework,"Implement comprehensive documentation requirements and processes covering training data provenance, system architecture, model cards, and component interactions to ensure transparent documentation of both the data lifecycle and system design.","Lack of training data transparency, Over- or under-reliance and unsafe use, Inadequate AI literacy and communication","- Explainability & Transparency
- Human-AI Interaction","- EU-DEPLOYER.C1
- EU-PROVIDER.C4
- EU-PROVIDER.C6
- EU-FM.C1
- ISO-42001.C14
- ISO-42001.C18"
CREDO-010,Implement AI system monitoring and logging infrastructure,"Deploy comprehensive monitoring and logging systems that capture AI system behavior, decisions, performance metrics, and real-time data source usage at multiple levels of granularity for full system observability, including tracking of data lineage during inference.","Inadequate observability, AI deception, Oversight and evaluation challenges, Lack of inference data transparency","- Explainability & Transparency
- Human-AI Interaction
- Performance & Robustness","- EU-DEPLOYER.C3
- EU-PROVIDER.C5
- EUAI-IV.C4"
CREDO-011,Establish AI decision explanation framework,"Implement mechanisms and tools for generating human-understandable explanations of AI system decisions, including feature importance, decision paths, confidence levels, and clear attribution of data sources and their characteristics used during inference.","Black box decision-making, Over- or under-reliance and unsafe use, Lack of inference data transparency","- Explainability & Transparency
- Human-AI Interaction",
CREDO-012,Establish and apply performance testing and validation framework,"Implement comprehensive performance requirements, testing protocols, and validation procedures to ensure AI systems meet capability requirements and maintain reliable operation across intended use cases.","Lack of adequate capabilities, Oversight and evaluation challenges",- Performance & Robustness,- CO-DEPLOYER.C1
CREDO-014,Establish and apply fairness testing and validation framework,"Implement comprehensive procedures to validate model fairness during development and pre-deployment, including test dataset creation, metric definition, and systematic assessment of performance disparities across demographic groups. ","Stereotype perpetuation, Unequal access to AI benefits",- Fairness & Bias,"- CO-DEPLOYER.C1
- EU-PROVIDER.C2"
CREDO-015,Implement fairness monitoring and remediation system,"Deploy continuous monitoring systems to detect fairness issues in production, including automated drift detection, performance disparity alerts, and systematic remediation procedures. ","Stereotype perpetuation, Unequal access to AI benefits",- Fairness & Bias,"- EXAMPLE-001
- CO-DEPLOYER.C3"
CREDO-016,Establish universal access and performance design framework,"Establish and follow a structured framework ensuring the AI system is designed and developed to deliver consistent, high-quality performance and accessibility for all intended user groups, regardless of their characteristics or circumstances.","Stereotype perpetuation, Unequal access to AI benefits, Lack of adequate capabilities","- Fairness & Bias
- Performance & Robustness",
CREDO-017,Establish content safety policy and boundaries,"Define and document comprehensive content safety policies, including prohibited content categories, acceptable content guidelines, output constraints, and required safeguards. Establish clear thresholds, classification criteria, and escalation levels for different types of harmful content. Include specific criteria for content that could enable or promote malicious use.","Toxic content, Obscene and sexually abusive content, Dangerous or violent content, ""Fraud, scams, and targeted manipulation"", ""Cyberattacks, weapon development, and mass harm"", AI pursuing its own goals in conflict with human goals or values","- Harmful Content
- Malicious Use
- AI Agency",- EU-LIMITED.C4
CREDO-018,Implement content moderation system,"Implement automated and/or human-in-the-loop content moderation mechanisms to detect and filter harmful content in real-time, including content classification, blocking procedures, and automated enforcement of safety boundaries. Include detection of potential malicious use patterns.","Toxic content, Obscene and sexually abusive content, Dangerous or violent content, ""Fraud, scams, and targeted manipulation"", ""Cyberattacks, weapon development, and mass harm""","- Harmful Content
- Malicious Use",
CREDO-019,Implement content safety incident response,"Establish procedures for investigating, documenting, and remediating harmful content incidents that bypass moderation systems, including coordination with relevant authorities, root cause analysis, and system improvement protocols. Include specific procedures for suspected malicious use cases.","Toxic content, Obscene and sexually abusive content, Dangerous or violent content, ""Fraud, scams, and targeted manipulation"", ""Cyberattacks, weapon development, and mass harm""","- Harmful Content
- Malicious Use",
CREDO-021,Establish frontier AI safety framework,"Establish and enforce policies governing system AI scaling decisions, including risk assessment requirements, capability thresholds, and deployment constraints. Define clear criteria for when and how system capabilities can be expanded based on safety considerations.","""Cyberattacks, weapon development, and mass harm"", AI pursuing its own goals in conflict with human goals or values, AI possessing dangerous capabilities, Coordinated influence operations, Mass surveillance and privacy attacks","- Malicious Use
- AI Agency",
CREDO-022,Implement adversarial testing and red team program,"Conduct systematic adversarial testing and red team exercises focused on probing AI system capabilities, identifying potential misuse vectors, and exposing unintended harmful behaviors. Testing should explore ways the system could be manipulated to produce dangerous outputs, bypass safety guardrails, or exhibit undesired emergent behaviors. Include scenarios involving both individual and coordinated attempts to exploit the system's capabilities.","AI pursuing its own goals in conflict with human goals or values, AI possessing dangerous capabilities, Lack of robustness, Coordinated influence operations, Mass surveillance and privacy attacks, ""Fraud, scams, and targeted manipulation"", ""Cyberattacks, weapon development, and mass harm""","- Malicious Use
- Performance & Robustness
- AI Agency",
CREDO-023,Implement system usage monitoring and prevention,"Monitor and prevent malicious or otherwise disallowed behavioral patterns including automated abuse, coordination across accounts, and systematic manipulation attempts. ","""Fraud, scams, and targeted manipulation"", ""Cyberattacks, weapon development, and mass harm"", Compromised personally identifiable information,  Coordinated influence operations, Mass surveillance and privacy attacks","- Malicious Use
- Privacy",
CREDO-026,Implement a privacy protection framework,"Implement comprehensive privacy protection measures to prevent exposure of PII and sensitive information, including data minimization, anonymization procedures, and privacy-preserving inference techniques.","Compromised sensitive information, Compromised personally identifiable information",- Privacy,- EU-DEPLOYER.C5
CREDO-028,Establish user rights and recourse framework,"Implement comprehensive mechanisms for user reporting, feedback collection, incident investigation, and recourse provision, including clear procedures for users to report issues, request explanations or corrections, appeal decisions, and receive appropriate remediation. The system should handle various types of user concerns including system errors, unfair treatment, privacy violations, and safety issues.","Over- or under-reliance and unsafe use, Stereotype perpetuation, Unequal access to AI benefits, Lack of robustness","- Fairness & Bias
- Human-AI Interaction
- Performance & Robustness",- CO-DEPLOYER.C5
CREDO-029,Implement AI literacy and competency program,"Implement comprehensive training and education programs to ensure personnel develop and maintain appropriate levels of AI literacy, risk awareness, and operational competency. This includes role-based training on AI capabilities, limitations, safety protocols, ethical considerations, and proper system usage.","Inadequate AI literacy and communication, Over- or under-reliance and unsafe use, Governance failures","- Human-AI Interaction
- Societal Impact","- EXAMPLE-001
- ISO-42001.C15"
CREDO-032,Implement environmental impact management system,"Implement comprehensive environmental impact monitoring and optimization procedures, including energy efficiency measures, carbon footprint tracking, and hardware lifecycle management.",Environmental harm,- Environmental Harm,
CREDO-035,Establish societal impact assessment framework,"Implement comprehensive processes for assessing and documenting potential societal impacts of AI systems, including effects on employment, economic systems, power dynamics, and cultural value. Include stakeholder consultation and impact mitigation planning.","Increased inequality and decline in employment quality, Economic and cultural devaluation of human effort, Power centralization and unfair distribution of benefits",- Societal Impact,"- CO-DEPLOYER.C2
- EU-DEPLOYER.C7
- ISO-42001.C11"
CREDO-036,Establish responsible development and deployment policy,"Establish policies and procedures governing AI system development and deployment decisions that consider societal implications, including competitive pressures, governance gaps, and benefit distribution. ","Competitive dynamics, Governance failures, Power centralization and unfair distribution of benefits, Environmental harm","- Environmental Harm
- Societal Impact",- ISO-42001.C6
CREDO-037,Implement AI alignment validation system,"Establish processes for validating and maintaining AI system alignment with human values and goals, including testing for goal preservation, monitoring for objective drift, and validation of decision-making processes against ethical standards. Includes specific attention to detecting and preventing potentially misaligned behaviors, emergent goals, or deceptive actions. Covers using interpretability techniques to measure and assure alignment with intended goals.","AI pursuing its own goals in conflict with human goals or values, AI possessing dangerous capabilities, Black box decision-making","- Explainability & Transparency
- AI Agency",